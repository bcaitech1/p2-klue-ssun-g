{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day6_실습자료_1_두_문장_관계_분류_학습.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF_mxF623B9w"
      },
      "source": [
        "# BERT 모델을 활용한 두 문장 관계 분류 학습\n",
        "\n",
        "> 작성자      \n",
        "```\n",
        "* 김성현 (bananaband657@gmail.com)  \n",
        "김바다 (qkek983@gmail.com)\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "```\n",
        "[CC BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/2.0/kr/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_b6wfJIGHTB",
        "outputId": "1e87ed0b-a2a2-41b2-871e-e3f1f956f266"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui1szMaGGWgN",
        "outputId": "136ac1b4-1ef4-4957-bcc6-723923d25277"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1L78IsQGk_Y"
      },
      "source": [
        "import torch\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIzOUKKNHAd2"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-RTgWyUHIy-",
        "outputId": "d047087b-d278-4426-9f6c-fdca6b06adb6"
      },
      "source": [
        "data = open(f'./drive/MyDrive/Colab Notebooks/para_kqc_sim_data.txt', 'r', encoding='utf-8')\n",
        "lines = data.readlines()\n",
        "\n",
        "# 데이터셋 구조 확인\n",
        "print(lines[0:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['메일을 다 비울까 아니면 안읽은 것만 지울까?\\t메일 중에 안읽은 것만 지울까? 다 지울까?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t안읽은 메일만 지워 다지워?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t다 지울까 안읽은 메일만 지울까?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t전체를 비울까 안읽은 것만 비울까?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t안읽은 메일만 지울꺼야? 아니면 다 지울꺼야?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t어떻게 지울까? 안읽은거만? 전체 다?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t메일을 다 지울지 안읽은거만 지울지 알려주세요\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t메일은 다 지울수도 있고, 안읽은거만 지울 수도 있어. 어떻게 할래?\\t1\\n', '메일을 다 비울까 아니면 안읽은 것만 지울까?\\t안읽은 메일만 지우든가, 다 지울 수 있는데 어떻게 할꺼야?\\t1\\n', '지메일 쓸래, 네이버 메일 쓸래\\t지메일을 쓸거야 네이버 메일을 쓸꺼야?\\t1\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrXn7xCee9c7"
      },
      "source": [
        "import random\n",
        "random.shuffle(lines)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H9JbybBfplB"
      },
      "source": [
        "train = {'sent_a':[], 'sent_b':[], 'label':[]}\n",
        "test = {'sent_a':[], 'sent_b':[], 'label':[]}\n",
        "for i, line in enumerate(lines):\n",
        "    if i < len(lines) * 0.8:\n",
        "        line = line.strip()\n",
        "        train['sent_a'].append(line.split('\\t')[0])\n",
        "        train['sent_b'].append(line.split('\\t')[1])\n",
        "        train['label'].append(int(line.split('\\t')[2]))\n",
        "    else:\n",
        "        line = line.strip()\n",
        "        test['sent_a'].append(line.split('\\t')[0])\n",
        "        test['sent_b'].append(line.split('\\t')[1])\n",
        "        test['label'].append(int(line.split('\\t')[2]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkuLX1RQfmxk"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIw0X-Zfg5F"
      },
      "source": [
        "train_data = pd.DataFrame({\"sent_a\":train['sent_a'], \"sent_b\":train['sent_b'], \"label\":train['label']})\n",
        "test_data = pd.DataFrame({\"sent_a\":test['sent_a'], \"sent_b\":test['sent_b'], \"label\":test['label']})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZosM0TofNqjP",
        "outputId": "e7a9acc9-220e-40ce-e76f-640bd59186b6"
      },
      "source": [
        "# 데이터 중복을 제외한 갯수 확인\n",
        "print(\"학습데이터 : \",train_data.groupby(['sent_a', 'sent_b']).ngroups,\" 라밸 : \",train_data['label'].nunique())\n",
        "print(\"데스트 데이터 : \",test_data.groupby(['sent_a', 'sent_b']).ngroups,\" 라벨 : \",test_data['label'].nunique())\n",
        "\n",
        "# 중복 데이터 제거\n",
        "train_data.drop_duplicates(subset=['sent_a', 'sent_b'], inplace= True)\n",
        "test_data.drop_duplicates(subset=['sent_a', 'sent_b'], inplace= True)\n",
        "\n",
        "# 데이터셋 갯수 확인\n",
        "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
        "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습데이터 :  15184  라밸 :  2\n",
            "데스트 데이터 :  3796  라벨 :  2\n",
            "중복 제거 후 학습 데이터셋 : 15184\n",
            "중복 제거 후 테스트 데이터셋 : 3796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHM43CnyP-1m"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glbzx0JWQlIe",
        "outputId": "3076192e-c81f-406b-c037-af1e09a67b78"
      },
      "source": [
        "# null 데이터 제거\n",
        "train_data.replace('', np.nan, inplace=True)\n",
        "test_data.replace('', np.nan, inplace=True)\n",
        "\n",
        "train_data = train_data.dropna(how = 'any')\n",
        "test_data = test_data.dropna(how = 'any')\n",
        "\n",
        "print('null 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
        "print('null 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "null 제거 후 학습 데이터셋 : 15184\n",
            "null 제거 후 테스트 데이터셋 : 3796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw0huiSARvNf",
        "outputId": "7f834b6a-b166-4588-ed30-25c4b6700e3f"
      },
      "source": [
        "print(train_data['sent_a'][0])\n",
        "print(train_data['sent_b'][0])\n",
        "print(train_data['label'][0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "트위치 계정에 메일을 몇개 등록할 수 있니?\n",
            "받은 메일함에 최대 몇 통의 메일을 저장할 수 있나요?\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "GchiPB9xSl6X",
        "outputId": "d1c2dc46-7a1d-4c92-ba58-9acb6e80ec2d"
      },
      "source": [
        "# 학습 전제 문장 길이조사\n",
        "print('학습 전제 문장의 최대 길이 :',max(len(l) for l in train_data['sent_a']))\n",
        "print('전제 문장의 평균 길이 :',sum(map(len, train_data['sent_a']))/len(train_data['sent_a']))\n",
        "\n",
        "plt.hist([len(s) for s in train_data['sent_a']], bins=50)\n",
        "plt.xlabel('length of data')\n",
        "plt.ylabel('number of data')\n",
        "plt.show()\n",
        "\n",
        "# 학습 가정 문장 길이조사\n",
        "print('학습 가정 문장의 최대 길이 :',max(len(l) for l in train_data['sent_b']))\n",
        "print('가정 문장의 평균 길이 :',sum(map(len, train_data['sent_b']))/len(train_data['sent_b']))\n",
        "\n",
        "plt.hist([len(s) for s in train_data['sent_b']], bins=50)\n",
        "plt.xlabel('length of data')\n",
        "plt.ylabel('number of data')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습 전제 문장의 최대 길이 : 49\n",
            "전제 문장의 평균 길이 : 22.362881981032665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "학습 가정 문장의 최대 길이 : 65\n",
            "가정 문장의 평균 길이 : 25.573761854583772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LReVjpgBS-ZA"
      },
      "source": [
        "# Store the model we want to use\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVIsxeRKTpKX"
      },
      "source": [
        "tokenized_train_sentences = tokenizer(\n",
        "    list(train_data['sent_a'][0:]),\n",
        "    list(train_data['sent_b'][0:]),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEhKDxEGT0I3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe4b3bb-06b7-4eb7-8d9a-8c35972b2dca"
      },
      "source": [
        "print(tokenized_train_sentences[0])\n",
        "print(tokenized_train_sentences[0].tokens)\n",
        "print(tokenized_train_sentences[0].ids)\n",
        "print(tokenized_train_sentences[0].attention_mask)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=64, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['[CLS]', '트', '##위', '##치', '계', '##정에', '메', '##일', '##을', '몇', '##개', '등', '##록', '##할', '수', '있', '##니', '?', '[SEP]', '받은', '메', '##일', '##함', '##에', '최대', '몇', '통', '##의', '메', '##일', '##을', '저', '##장', '##할', '수', '있', '##나', '##요', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "[101, 9890, 19855, 18622, 8887, 77763, 9272, 18392, 10622, 9282, 21789, 9121, 31398, 14843, 9460, 9647, 25503, 136, 102, 74141, 9272, 18392, 48533, 10530, 99405, 9282, 9879, 10459, 9272, 18392, 10622, 9663, 13890, 14843, 9460, 9647, 16439, 48549, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqLNtUO4Uzvr"
      },
      "source": [
        "tokenized_test_sentences = tokenizer(\n",
        "    list(test_data['sent_a'][0:]),\n",
        "    list(test_data['sent_b'][0:]),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64\n",
        "    )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FENrKAYTeRrY"
      },
      "source": [
        "train_label = train_data['label'].values[0:]\n",
        "test_label = test_data['label'].values[0:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPkvybQXedLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05933333-e9a0-49c8-c442-4596529e8300"
      },
      "source": [
        "print(train_label[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UQZfgftemeQ"
      },
      "source": [
        "class MultiSentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsuVdy45esNO"
      },
      "source": [
        "train_dataset = MultiSentDataset(tokenized_train_sentences, train_label)\n",
        "test_dataset = MultiSentDataset(tokenized_test_sentences, test_label)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6CwUYuMe-3v"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments,  BertConfig\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    metric_for_best_model='accuracy',\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WszEeM0_eAa",
        "outputId": "01b682a0-2aaf-4d58-e242-25f312baf04a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) \n",
        "model.parameters\n",
        "model.to(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkQd-h-0mcFU"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDKBd25q_61i"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,             # evaluation dataset\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG2_c2K0AYGD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "49a4f67f-52bf-44c6-b564-d3805205768f"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='5694' max='5694' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5694/5694 32:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.326500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.282300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.244500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.190400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.163300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.151000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.111300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.097500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.077200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.055400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5694, training_loss=0.15614648664211198, metrics={'train_runtime': 1954.2693, 'train_samples_per_second': 2.914, 'total_flos': 3111033583816704.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 8192, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -744865792, 'train_mem_gpu_alloc_delta': 2144760320, 'train_mem_cpu_peaked_delta': 758116352, 'train_mem_gpu_peaked_delta': 427753984})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "K9NoRHuVlcv-",
        "outputId": "12d6d732-1368-4bb2-bc19-ec94501c30ae"
      },
      "source": [
        "trainer.evaluate(eval_dataset=test_dataset)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:26]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.981822971548999,\n",
              " 'eval_f1': 0.9810595662915179,\n",
              " 'eval_loss': 0.10425252467393875,\n",
              " 'eval_mem_cpu_alloc_delta': 1851392,\n",
              " 'eval_mem_cpu_peaked_delta': 0,\n",
              " 'eval_mem_gpu_alloc_delta': 0,\n",
              " 'eval_mem_gpu_peaked_delta': 138603520,\n",
              " 'eval_precision': 0.9781061850027367,\n",
              " 'eval_recall': 0.9840308370044053,\n",
              " 'eval_runtime': 27.0119,\n",
              " 'eval_samples_per_second': 140.531}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMRlb9khzrp"
      },
      "source": [
        "trainer.save_model('./results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIUdBIN8AiG6"
      },
      "source": [
        "# native training using torch\n",
        "\n",
        "# bert_config = BertConfig.from_pretrained(MODEL_NAME)\n",
        "# bert_config.num_labels = 3\n",
        "# model = BertForSequenceClassification(bert_config) \n",
        "# model.to(device)\n",
        "# model.train()\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# for epoch in range(3):\n",
        "#     for batch in train_loader:\n",
        "#         optim.zero_grad()\n",
        "#         input_ids = batch['input_ids'].to(device)\n",
        "#         attention_mask = batch['attention_mask'].to(device)\n",
        "#         labels = batch['labels'].to(device)\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "#         loss = outputs[0]\n",
        "#         loss.backward()\n",
        "#         optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlWK5Y3TAlQZ"
      },
      "source": [
        "# predict함수\n",
        "# 0: \"non_similar\", 1: \"similar\"\n",
        "def sentences_predict(sent_A, sent_B):\n",
        "    model.eval()\n",
        "    tokenized_sent = tokenizer(\n",
        "            sent_A,\n",
        "            sent_B,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=64\n",
        "    )\n",
        "    \n",
        "    tokenized_sent.to('cuda:0')\n",
        "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
        "        outputs = model(\n",
        "            input_ids=tokenized_sent['input_ids'],\n",
        "            attention_mask=tokenized_sent['attention_mask'],\n",
        "            token_type_ids=tokenized_sent['token_type_ids']\n",
        "            )\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits)\n",
        "\n",
        "    if result == 0:\n",
        "      result = 'non_similar'\n",
        "    elif result == 1:\n",
        "      result = 'similar'\n",
        "    return result"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-1Pw1iSA2FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3e057d-7b0b-4d05-b578-4bd8b12cca01"
      },
      "source": [
        "print(sentences_predict('오늘 날씨가 어때요?','오늘의 날씨를 알려줘')) # similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','기분 진짜 안좋다.')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분 어떠세요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','오늘 기분이 어때요?')) # non_similar\n",
        "print(sentences_predict('오늘 날씨가 어때요?','지금 날씨가 어때요?')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 장르의 소설 추천 부탁드립니다.')) # similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','판타지 소설 추천해주세요.')) # non_similar\n",
        "print(sentences_predict('무협 소설 추천해주세요.','무협 느낌나는 소설 하나 추천해주실 수 있으실까요?')) # similar"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similar\n",
            "non_similar\n",
            "non_similar\n",
            "non_similar\n",
            "similar\n",
            "similar\n",
            "non_similar\n",
            "similar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKclArygqcrM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}