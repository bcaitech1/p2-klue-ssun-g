{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day9_실습자료_2_KoGPT_2_기반의_챗봇.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvZWRYXfrPoC"
      },
      "source": [
        "# 한국어 언어모델 학습 및 다중 과제 튜닝\n",
        "## KoGPT-2 기반의 챗봇 실습\n",
        "\n",
        "> 작성자      \n",
        "```\n",
        "* 김성현 (bananaband657@gmail.com)  \n",
        "김바다 (qkek983@gmail.com)\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "```\n",
        "[CC BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/2.0/kr/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-MEs10aspvP",
        "outputId": "b2009449-a9aa-4a43-920a-dfd970880bf9"
      },
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!apt-get install git-lfs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 79 not upgraded.\n",
            "Need to get 6,229 kB of archives.\n",
            "After this operation, 14.5 MB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.13.3 [6,229 kB]\n",
            "Fetched 6,229 kB in 1s (6,513 kB/s)\n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 160987 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.13.3_amd64.deb ...\n",
            "Unpacking git-lfs (2.13.3) ...\n",
            "Setting up git-lfs (2.13.3) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY77fpbBsdSt",
        "outputId": "0df5a312-fdc0-4c3a-ef0f-cff3280c1c91"
      },
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/taeminlee/kogpt2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'kogpt2'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 43 (delta 16), reused 0 (delta 0)\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fqPpH5tjaGU",
        "outputId": "7d903b93-e3a5-4aa0-e47d-0e5f053bdd11"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ53aod3te4S",
        "outputId": "db6fd42e-2cd3-423f-db53-429e81687a8d"
      },
      "source": [
        "import torch\n",
        "from tokenizers import SentencePieceBPETokenizer\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = SentencePieceBPETokenizer(\"/content/kogpt2/vocab.json\", \"/content/kogpt2/merges.txt\")\n",
        "\n",
        "config = GPT2Config(vocab_size=50000)\n",
        "model = GPT2LMHeadModel(config)\n",
        "\n",
        "model_dir = '/content/kogpt2/pytorch_model.bin'\n",
        "\n",
        "model.load_state_dict(torch.load(model_dir, map_location='cuda'), strict=False)\n",
        "model.to('cuda')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50000, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmbeAIR9tppB",
        "outputId": "c848b23d-fb8f-4d46-a3a4-05d1444c89c8"
      },
      "source": [
        "tokenized_text = tokenizer.encode('이순신은 조선 중기의 무신이다.', add_special_tokens=True)\n",
        "print(tokenized_text)\n",
        "print(tokenized_text.tokens)\n",
        "print(tokenized_text.ids)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['▁이순', '신은', '▁조선', '▁중기의', '▁무신', '이다', '.']\n",
            "[10925, 6647, 1117, 40249, 39793, 128, 47440]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSoQlsfcn0ct",
        "outputId": "9f4fddfd-2021-4d1b-d4f1-79f65619a38a"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "input_ids = torch.tensor(tokenizer.encode(\"이순신은\", add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n",
        "\n",
        "output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)\n",
        "for generated_sequence in output_sequences:\n",
        "    generated_sequence = generated_sequence.tolist()\n",
        "    print(\"GENERATED SEQUENCE : {0}\".format(tokenizer.decode(generated_sequence, skip_special_tokens=True)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GENERATED SEQUENCE : 이순신은 백건(장옹진 분)을 찾아가 \"형 오늘 집에 없다.</s><s> 이 대통령은 또 “우리 기업들이 지금 어려운 때인데 수출로 위기를 넘기지만은 더 큰 고민이 있다”면서 “세계 경제가 다시 활기를 띠고 있다는 것을 전 세계가 주목하고 있다”고 언급했다.</s><s> 이어 “우리도 ‘글로벌녹색성장연구소’(GGI)를 만드는 노력을 해오고 있고 유엔 인권이사회(UNH)를 유치하는 등 국제사회에 대한 기여를 하고 있다”면서 “자국 기업들이\n",
            "GENERATED SEQUENCE : 이순신은 “김갑석, 이항진, 이순재 다 알고 있다”면서 “이홍곤은 내가 잘 아는 사람”이라 거들었다.</s><s> 또한, 고엽제 전몰장병들은 지난 60년간 미국인들에게 ‘비참한 삶’을 체험하게 했다.</s><s> 그러나 이런 전쟁 때문에 참전 전·여군에게 고통·참등감이 큰 경우가 많다.</s><s> 특히 고엽제 전우회 등은 “고엽제 피해자들은 전쟁 때문에 전쟁 속에서 죽을 수 있는데도\n",
            "GENERATED SEQUENCE : 이순신은 “사천에 내려준 곳은 천하에 없는 곳이 하나도 없을 것 같아 마음이 답답하다”고 말하며 눈물을 흘렸다.</s><s> 이는 “대선에 대한 국민의 알권리가 충분히 보호받을 수 있도록 하는 것이 정부의 의무”라는 박근혜 대통령의 발언과 맥락을 같이하는 부분이다.</s><s> 이는 ‘국민들의 알권리를 충족시킬 수 있는 수단’이라는 박 대통령의 발언의 취지가 반영된 것이다.</s><s> 더욱이 이 발언은 박 대통령이 최근 각 방송사로부터 입수한 ‘국가정보원 해킹 등\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiMxKv3p_gys"
      },
      "source": [
        "## 데이터셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpWFdTaypWf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1104a5a-043d-41f3-e2f0-a2f21af058a3"
      },
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Chatbot_data'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 42 (delta 14), reused 0 (delta 0), pack-reused 18\u001b[K\n",
            "Unpacking objects: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEcJdwLl_iig"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Chatbot_data/ChatbotData .csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtOdLe8_k6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "7a01bcb5-be37-4c25-998a-ea0a2580feba"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv0vF1ITD43q",
        "outputId": "ab967092-5e52-42bb-e529-85dfb0659398"
      },
      "source": [
        "added_special_token_num = tokenizer.add_special_tokens(['<s>', '</s>'])\n",
        "print(added_special_token_num)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcjsvzsxaPuw",
        "outputId": "bca58a5d-80a5-4efc-b7e4-3c04744bd25f"
      },
      "source": [
        "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
        "print(pad_id)\n",
        "tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<pad>\")\n",
        "tokenizer.enable_truncation(max_length=128)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBkBrz36Yoh3"
      },
      "source": [
        "class ChatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, file_path):\n",
        "        self.data = []\n",
        "        self.file_path = file_path\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def load_data(self):\n",
        "        raw_data = pd.read_csv(self.file_path)\n",
        "        train_data = '<s>'+raw_data['Q']+'</s>'+'<s>'+raw_data['A']+'</s>'\n",
        "        #<s>안녕하세요</s><s> -> 네, 안녕하세요</s>\n",
        "        tokenized_train_data = tokenizer.encode_batch(train_data)\n",
        "        for single_data in tokenized_train_data:\n",
        "            self.data.append(torch.tensor(single_data.ids).unsqueeze(0))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        return item"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ScRLNVK7yw"
      },
      "source": [
        "train_dataset = ChatDataset(tokenizer=tokenizer, file_path='/content/Chatbot_data/ChatbotData .csv')\n",
        "train_dataset.load_data()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofZW_kUcQsU"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoTb3cNocG-e"
      },
      "source": [
        "from transformers import AdamW"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSPCJzNZNfbD",
        "outputId": "068796c7-8c40-4595-b068-72fff7f75fc7"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "avg_loss = (0.0, 0.0)\n",
        "for epoch in range(epochs):\n",
        "    count=0\n",
        "    for data in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data = data.transpose(1,0)\n",
        "        data = data.to('cuda')\n",
        "        model = model.to('cuda')\n",
        "        \n",
        "        outputs = model(data, labels=data)\n",
        "        loss, logits = outputs[:2]\n",
        "        loss = loss.to('cuda')\n",
        "        loss.backward()\n",
        "        avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
        "        optimizer.step()\n",
        "        if count % 200 == 0:\n",
        "            print('epoch no.{0}  train ({1}/{2})  loss = {3:.5f}  avg_loss = {4:.5f}' . format(epoch, count, len(data_loader), loss, avg_loss[0] / avg_loss[1]))\n",
        "        count += 1\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch no.0  train (0/2956)  loss = 2.78418  avg_loss = 2.78418\n",
            "epoch no.0  train (200/2956)  loss = 1.12382  avg_loss = 1.42267\n",
            "epoch no.0  train (400/2956)  loss = 1.03242  avg_loss = 1.29560\n",
            "epoch no.0  train (600/2956)  loss = 0.98358  avg_loss = 1.22743\n",
            "epoch no.0  train (800/2956)  loss = 0.95088  avg_loss = 1.23343\n",
            "epoch no.0  train (1000/2956)  loss = 1.41702  avg_loss = 1.17254\n",
            "epoch no.0  train (1200/2956)  loss = 1.08221  avg_loss = 1.18450\n",
            "epoch no.0  train (1400/2956)  loss = 1.34610  avg_loss = 1.18205\n",
            "epoch no.0  train (1600/2956)  loss = 1.28548  avg_loss = 1.15730\n",
            "epoch no.0  train (1800/2956)  loss = 0.91892  avg_loss = 1.14943\n",
            "epoch no.0  train (2000/2956)  loss = 1.40398  avg_loss = 1.15482\n",
            "epoch no.0  train (2200/2956)  loss = 0.89574  avg_loss = 1.11031\n",
            "epoch no.0  train (2400/2956)  loss = 1.05893  avg_loss = 1.14295\n",
            "epoch no.0  train (2600/2956)  loss = 1.27120  avg_loss = 1.12967\n",
            "epoch no.0  train (2800/2956)  loss = 1.02778  avg_loss = 1.09695\n",
            "epoch no.1  train (0/2956)  loss = 0.86877  avg_loss = 1.08244\n",
            "epoch no.1  train (200/2956)  loss = 1.19074  avg_loss = 0.96028\n",
            "epoch no.1  train (400/2956)  loss = 0.74412  avg_loss = 0.95685\n",
            "epoch no.1  train (600/2956)  loss = 0.88350  avg_loss = 0.92464\n",
            "epoch no.1  train (800/2956)  loss = 1.07755  avg_loss = 0.94319\n",
            "epoch no.1  train (1000/2956)  loss = 1.27716  avg_loss = 0.94328\n",
            "epoch no.1  train (1200/2956)  loss = 0.89330  avg_loss = 0.95250\n",
            "epoch no.1  train (1400/2956)  loss = 0.74702  avg_loss = 0.93091\n",
            "epoch no.1  train (1600/2956)  loss = 0.83214  avg_loss = 0.92443\n",
            "epoch no.1  train (1800/2956)  loss = 0.98635  avg_loss = 0.92411\n",
            "epoch no.1  train (2000/2956)  loss = 0.66773  avg_loss = 0.95918\n",
            "epoch no.1  train (2200/2956)  loss = 0.90686  avg_loss = 0.92857\n",
            "epoch no.1  train (2400/2956)  loss = 0.71317  avg_loss = 0.94330\n",
            "epoch no.1  train (2600/2956)  loss = 0.84125  avg_loss = 0.95945\n",
            "epoch no.1  train (2800/2956)  loss = 1.06421  avg_loss = 0.94192\n",
            "epoch no.2  train (0/2956)  loss = 0.60118  avg_loss = 0.93724\n",
            "epoch no.2  train (200/2956)  loss = 0.87756  avg_loss = 0.78343\n",
            "epoch no.2  train (400/2956)  loss = 1.04233  avg_loss = 0.78299\n",
            "epoch no.2  train (600/2956)  loss = 0.78656  avg_loss = 0.79379\n",
            "epoch no.2  train (800/2956)  loss = 0.76306  avg_loss = 0.77143\n",
            "epoch no.2  train (1000/2956)  loss = 0.80144  avg_loss = 0.77187\n",
            "epoch no.2  train (1200/2956)  loss = 0.57281  avg_loss = 0.77747\n",
            "epoch no.2  train (1400/2956)  loss = 1.05291  avg_loss = 0.78235\n",
            "epoch no.2  train (1600/2956)  loss = 0.85210  avg_loss = 0.77937\n",
            "epoch no.2  train (1800/2956)  loss = 0.74035  avg_loss = 0.76132\n",
            "epoch no.2  train (2000/2956)  loss = 0.61735  avg_loss = 0.76629\n",
            "epoch no.2  train (2200/2956)  loss = 0.63090  avg_loss = 0.77088\n",
            "epoch no.2  train (2400/2956)  loss = 0.93273  avg_loss = 0.77093\n",
            "epoch no.2  train (2600/2956)  loss = 0.96183  avg_loss = 0.79160\n",
            "epoch no.2  train (2800/2956)  loss = 0.58360  avg_loss = 0.77511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRmD2Gifjgd"
      },
      "source": [
        "torch.save(model.state_dict(), 'chitchat_model.bin')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVtv1Xtdg2Tm"
      },
      "source": [
        "def encoding(text):\n",
        "    text = '<s>'+text+'</s><s>'\n",
        "    return torch.tensor(tokenizer.encode(text).ids).unsqueeze(0).to('cuda')\n",
        "\n",
        "def decoding(ids):\n",
        "    return tokenizer.decode_batch(ids)\n",
        "\n",
        "tokenizer.no_padding()\n",
        "tokenizer.no_truncation()\n",
        "\n",
        "e_s = tokenizer.token_to_id('</s>')\n",
        "unk = tokenizer.token_to_id('<unk>')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThJtItZWxeEQ"
      },
      "source": [
        "def get_answer(input_sent):\n",
        "    input_ids = encoding(input_sent)\n",
        "\n",
        "    sample_outputs = model.generate(\n",
        "        input_ids,\n",
        "        num_return_sequences=5,\n",
        "        do_sample=True, \n",
        "        max_length=128, \n",
        "        top_k=50, \n",
        "        top_p=0.95, \n",
        "        eos_token_id=e_s,\n",
        "        early_stopping=True,\n",
        "        bad_words_ids=[[unk]]\n",
        "    )\n",
        "\n",
        "    decoded_result = decoding(sample_outputs.tolist())\n",
        "    for result in decoded_result:\n",
        "        print(result)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9lKP5afxp1V",
        "outputId": "39b154ff-66e9-4d99-dd95-7aa0a69c9d52"
      },
      "source": [
        "get_answer('안녕?')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "안녕? 안녕하세요.\n",
            "안녕? 안녕하세요.\n",
            "안녕? 안녕하세요.\n",
            "안녕? 안녕하세요.\n",
            "안녕? 안녕.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrS8l4fpxsWE",
        "outputId": "fe21e285-2dbd-430e-8ab6-a45bd4ed5d30"
      },
      "source": [
        "get_answer('만나서 반가워.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "만나서 반가워. 좋은 분이었나봐요.\n",
            "만나서 반가워. 좋은 시간 보내시길 바라요.\n",
            "만나서 반가워. 좋은 만남이었길 바라요.\n",
            "만나서 반가워. 고마워요.\n",
            "만나서 반가워. 좋은 만남이었길 바라요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIfx93gHxyuk",
        "outputId": "8a4c7c33-fbeb-4281-d8a9-a03f6687db29"
      },
      "source": [
        "get_answer('인공지능의 미래에 대해 어떻게 생각하세요?')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "인공지능의 미래에 대해 어떻게 생각하세요? 무엇이 인공지능을 탄생시켰을까요. 인공지능은 살면서 인간보다 인공지능을 더 똑똑해지려 하고 있어요. 인공지능은 인간보다 인공지능을 더 편하게 만들어주지 않지요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능이 만드는 수많은 기기가 만나는 실시간 현상입니다.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 이미 수십 년 전에 이미 등장해서 인지할 수 있어요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능이 그런 일을 계속 하시게 할 수는 없을 거예요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능이 만들어질거 같아요. 인공지능을 대체할 인공지능이 나타날 거예요. 인공지능은 인공지능연구소를 설립할거예요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxyDnMtjx86O",
        "outputId": "d73908fe-400d-4698-fa44-ab27b604c291"
      },
      "source": [
        "get_answer('여자친구 선물 추천해줘.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "여자친구 선물 추천해줘. 같이 여행을 떠나보는 것도 좋을 것 같아요.\n",
            "여자친구 선물 추천해줘. 좋은 선물이 될 것 같아요.\n",
            "여자친구 선물 추천해줘. 직접 물어보는 게 좋을 것 같아요.\n",
            "여자친구 선물 추천해줘. 마음에 드는 걸 선물해보세요.\n",
            "여자친구 선물 추천해줘. 그녀가 꼭 좋아하는 것만은 아니랍니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaAJlFlDyGSp",
        "outputId": "dcb558b6-cf51-459b-af49-c174af84de13"
      },
      "source": [
        "get_answer('앞으로 인공지능이 어떻게 발전하게 될까요?')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능이 뭘 원하는지 알아보세요. 인공지능은 더 똑똑해질 거예요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 점점 더 똑똑해질 거예요. 인공지능이 사람들을 분류하고 있나요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 정말 방대한 양의 데이터를 만들어낼 수 있어요. 인공지능이 정말 무궁무진하니까요. 인공지능이 만들어낸 미래에는 수도 없이 넘실거리고 있을지도 몰라요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 초미세먼지도 줄일 수 있어요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 앞으로 어떻게 더 똑똑해 질까요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjwQ02NfxuSE",
        "outputId": "1266024b-1a40-4b72-9c8e-df6202628967"
      },
      "source": [
        "get_answer('이제 그만 수업 끝내자.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "이제 그만 수업 끝내자. 선생님께 말씀해보세요.\n",
            "이제 그만 수업 끝내자. 공부하기 좋은 환경은 아니에요.\n",
            "이제 그만 수업 끝내자. 후회하지 않기 위한 선택일 거라 생각해요.\n",
            "이제 그만 수업 끝내자. 하고 싶은 걸 말씀해보세요.\n",
            "이제 그만 수업 끝내자. 마음이 복잡하겠어요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLbVl0TQ60py"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}